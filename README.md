CrossMol: Cross-Modal Mask-Predict Pre-training For 3D Molecular Data
===================================================================
This is an official implement for CrossMol.

**Abstract**:
Self-supervised pre-training models for molecular data are attracting increasing attention and have demonstrated notable results across many downstream tasks. Moreover, the inherent multimodal properties of molecules have led to extensive efforts to capture the multimodal information contained in molecular data. However, current multimodal molecular pre-training models usually treat inputs from different modalities as equal and independent. Yet, the knowledge and information contained in different modalities can differ significantly. For example, 3D molecular structure data generally contain more and finer-grained knowledge than SMILES data and the SMILES data primarily contains higher-level semantic information, such as the molecular topology. In light of this, we designed a cross-modal mask-predict pre-training model, CrossMol, to better capture the semantic associations between modalities with unequal information volumes. In this approach, the model completes missing 3D structure using higher-level semantic information from different modality, such as SMILES. In this way, the model can learn cross-modal associations and further assist the model in better understanding finer-grained 3D structural information from multiple perspectives. Additionally, to improve the modeling ability of short-range structural information within 3D data, we introduce a new reweighted distance prediction loss function for structural pre-training. Our experiments show that the CrossMol achieves a large margin performance gain on multiple downstream molecular tasks, achieving state-of-the-art results.
